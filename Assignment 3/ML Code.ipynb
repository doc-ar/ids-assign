{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26/11/2023\n",
    "# CSC461 – Assignment3 – Machine Learning\n",
    "# AbdurRahman Khan\n",
    "# SP21-BSE-065\n",
    "# Applications of multiple machine learning techniques and algorithms on a common dataset from the provided file \"gender-prediction.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prerequisites: Importing Libraries and Basic BoilerPlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, LeavePOut\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "filename = \"gender-prediction.csv\"\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "1. How many instances does the dataset contain?\n",
    "2. How many input attributes does the dataset contain?\n",
    "3. How many possible values does the output attribute have?\n",
    "4. How many input attributes are categorical?\n",
    "5. What is the class ratio (male vs female) in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 110\n",
      "2. 8\n",
      "3. 2\n",
      "4. 5\n",
      "5. gender\n",
      "male      0.563636\n",
      "female    0.436364\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Number of instances\n",
    "num_instances, num_attributes = df.shape\n",
    "print(\"1. \" + str(num_instances))\n",
    "\n",
    "# 2. Number of attributes\n",
    "print(\"2. \" + str(num_attributes))\n",
    "\n",
    "# 3. Number of unique output values\n",
    "num_output_values = df['gender'].nunique()\n",
    "print(\"3. \" + str(num_output_values))\n",
    "\n",
    "# 4. Number of categorical inputs\n",
    "num_categorical_attributes = len(df.select_dtypes(include=['object']).columns)\n",
    "print(\"4. \" + str(num_categorical_attributes))\n",
    "\n",
    "# 5. Class ratio between Males and Females\n",
    "class_ratio = df['gender'].value_counts(normalize=True)\n",
    "print(\"5. \" + str(class_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Apply Logistic Regression, Support Vector Machines, and Multilayer Perceptron classification algorithms (using Python) on the gender prediction dataset with 2/3 train and 1/3 test split ratio and answer the following questions.\n",
    "1. How many misclassified instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weuse\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.8648648648648649 Misclassified Instances: 5\n",
      "Support Vector Machines - Accuracy: 0.7567567567567568 Misclassified Instances: 9\n",
      "Multilayer Perceptron - Accuracy: 0.8108108108108109 Misclassified Instances: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weuse\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['beard'] = label_encoder.fit_transform(df['beard'])\n",
    "df['hair_length'] = label_encoder.fit_transform(df['hair_length'])\n",
    "df['scarf'] = label_encoder.fit_transform(df['scarf'])\n",
    "df['eye_color'] = label_encoder.fit_transform(df['eye_color'])\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('gender', axis=1)\n",
    "y = df['gender']\n",
    "\n",
    "# Split the dataset into training and testing sets (2/3 train, 1/3 test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    misclassified_instances = (y_test != y_pred).sum()\n",
    "    return accuracy, misclassified_instances\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression()\n",
    "accuracy_logistic, misclassified_logistic = train_and_evaluate(logistic_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Support Vector Machines\n",
    "svm_model = SVC()\n",
    "accuracy_svm, misclassified_svm = train_and_evaluate(svm_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Multilayer Perceptron\n",
    "mlp_model = MLPClassifier()\n",
    "accuracy_mlp, misclassified_mlp = train_and_evaluate(mlp_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Logistic Regression - Accuracy:\", accuracy_logistic, \"Misclassified Instances:\", misclassified_logistic)\n",
    "print(\"Support Vector Machines - Accuracy:\", accuracy_svm, \"Misclassified Instances:\", misclassified_svm)\n",
    "print(\"Multilayer Perceptron - Accuracy:\", accuracy_mlp, \"Misclassified Instances:\", misclassified_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Repeat with 80/20 Train-Test split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weuse\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with 80/20 split:\n",
      "Logistic Regression - Accuracy: 1.0 Misclassified Instances: 0\n",
      "Support Vector Machines - Accuracy: 0.8181818181818182 Misclassified Instances: 4\n",
      "Multilayer Perceptron - Accuracy: 0.8636363636363636 Misclassified Instances: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weuse\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets (80/20 train/test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run the models again and print the results\n",
    "accuracy_logistic_80_20, misclassified_logistic_80_20 = train_and_evaluate(logistic_model, X_train, X_test, y_train, y_test)\n",
    "accuracy_svm_80_20, misclassified_svm_80_20 = train_and_evaluate(svm_model, X_train, X_test, y_train, y_test)\n",
    "accuracy_mlp_80_20, misclassified_mlp_80_20 = train_and_evaluate(mlp_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\nResults with 80/20 split:\")\n",
    "print(\"Logistic Regression - Accuracy:\", accuracy_logistic_80_20, \"Misclassified Instances:\", misclassified_logistic_80_20)\n",
    "print(\"Support Vector Machines - Accuracy:\", accuracy_svm_80_20, \"Misclassified Instances:\", misclassified_svm_80_20)\n",
    "print(\"Multilayer Perceptron - Accuracy:\", accuracy_mlp_80_20, \"Misclassified Instances:\", misclassified_mlp_80_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Name 2 attributes that you believe are the most “powerful” in the prediction task. Explain why?\n",
    "4. Try to exclude these 2 attribute(s) from the dataset. Rerun the experiment (using 80/20 train/test split),\n",
    "did you find any change in the results? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results after excluding attributes:\n",
      "Logistic Regression - Accuracy: 1.0 Misclassified Instances: 0\n",
      "Support Vector Machines - Accuracy: 0.7272727272727273 Misclassified Instances: 6\n",
      "Multilayer Perceptron - Accuracy: 0.45454545454545453 Misclassified Instances: 12\n"
     ]
    }
   ],
   "source": [
    "most_powerful_attributes = ['height', 'weight']\n",
    "\n",
    "# Exclude the identified attributes\n",
    "X_excluded = X.drop(most_powerful_attributes, axis=1)\n",
    "\n",
    "# Split the dataset into training and testing sets (80/20 train/test)\n",
    "X_train_excluded, X_test_excluded, y_train_excluded, y_test_excluded = train_test_split(X_excluded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run the models again with excluded attributes\n",
    "accuracy_logistic_excluded, misclassified_logistic_excluded = train_and_evaluate(logistic_model, X_train_excluded, X_test_excluded, y_train_excluded, y_test_excluded)\n",
    "accuracy_svm_excluded, misclassified_svm_excluded = train_and_evaluate(svm_model, X_train_excluded, X_test_excluded, y_train_excluded, y_test_excluded)\n",
    "accuracy_mlp_excluded, misclassified_mlp_excluded = train_and_evaluate(mlp_model, X_train_excluded, X_test_excluded, y_train_excluded, y_test_excluded)\n",
    "\n",
    "print(\"\\nResults after excluding attributes:\")\n",
    "print(\"Logistic Regression - Accuracy:\", accuracy_logistic_excluded, \"Misclassified Instances:\", misclassified_logistic_excluded)\n",
    "print(\"Support Vector Machines - Accuracy:\", accuracy_svm_excluded, \"Misclassified Instances:\", misclassified_svm_excluded)\n",
    "print(\"Multilayer Perceptron - Accuracy:\", accuracy_mlp_excluded, \"Misclassified Instances:\", misclassified_mlp_excluded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: Apply Random Forest classification algorithm (using Python) on the gender prediction dataset with Monte Carlo cross-validation and Leave P-Out cross-validation. Report F1 scores for both cross-validation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=1, random_state=42)\n",
    "\n",
    "# Function to perform Monte Carlo cross-validation and calculate F1 score\n",
    "def monte_carlo_cross_validation(X, y, classifier, num_iterations=3):\n",
    "    f1_scores = []\n",
    "    for _ in range(num_iterations):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None)  # No fixed random state for Monte Carlo\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    return f1_scores\n",
    "\n",
    "# Function to perform Leave P-Out cross-validation and calculate F1 score\n",
    "def leave_p_out_cross_validation(X, y, classifier, p=5):\n",
    "    f1_scores = []\n",
    "    lpo = LeavePOut(p=p)\n",
    "    for train_index, test_index in lpo.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    return f1_scores\n",
    "\n",
    "# Perform Monte Carlo cross-validation\n",
    "monte_carlo_f1_scores = monte_carlo_cross_validation(X, y, rf_classifier, num_iterations=10)\n",
    "\n",
    "# Perform Leave P-Out cross-validation with p=5\n",
    "leave_p_out_f1_scores = leave_p_out_cross_validation(X, y, rf_classifier, p=5)\n",
    "\n",
    "# Report the results\n",
    "print(\"Monte Carlo Cross-Validation F1 Scores:\", monte_carlo_f1_scores)\n",
    "print(\"Average F1 Score (Monte Carlo):\", sum(monte_carlo_f1_scores) / len(monte_carlo_f1_scores))\n",
    "\n",
    "print(\"\\nLeave P-Out Cross-Validation F1 Scores:\", leave_p_out_f1_scores)\n",
    "print(\"Average F1 Score (Leave P-Out):\", sum(leave_p_out_f1_scores) / len(leave_p_out_f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: Add 10 sample instances into the dataset (you can ask your friends/relatives/sibling for the data). Run the ML experiment (using Python) by training the model using Gaussian Naïve Bayes classification algorithm and all the instances from the gender prediction dataset. Evaluate the trained model using the newly added 10 test instances. Report accuracy, precision, and recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9545454545454546\n",
      "Precision: 0.9586776859504131\n",
      "Recall: 0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Initialize the Gaussian Naïve Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Train the model on the training set\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the gender for the test instances\n",
    "predictions = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Report the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
